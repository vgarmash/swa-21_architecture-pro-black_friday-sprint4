### <a name="_b7urdng99y53"></a>**Название:** Проектирование схем коллекций для шардирования данных
### <a name="_b7urdng99y53"></a>**Номер записи:** 1
### <a name="_hjk0fkfyohdk"></a>**Автор:** Дубовик Сергей Андреевич
### <a name="_hjk0fkfyohdk"></a>**Исполнитель:** Старший разрабочтик номер 2
### <a name="_uanumrh8zrui"></a>**Дата:** 02.08.2025
### <a name="_qmphm5d6rvi3"></a>**Контекст**
На текущий момент наблюдаются проблемы с расширением существующей платформы под новые категории товаров, ситуация располагает к проведению работ по декомпозиции системы и данных, проведения шардирования ключевых сущностей для превентивного реагирования на потенциальные проблемы с производительностью

### <a name="_u8xz25hbrgql"></a>**Нефункциональные требования**

|**№**|**Требование**|
| :-: | :- |
|1| Availability. SLA планируется на уровне 99.95% |
|2| Performance. Клиент должен получить ответ не более чем за 500мс |
|3| Scalability. Проблема хранения данных должна быть решена для объемов продаж х50 от текущих  |
---
### <a name="_qmphm5d6rvi3"></a>**Решение**

Для выбора метода шардирования необходимо описать текущие схемы базы и выбрать подходящий ключ в соотвествии с требованиями:

1. Высокое распределение (кардинальность)
2. Возможность точечных запросов к конкретному шарду (без scatter gather)
3. Избегание hotspot
4. Редкоизменяемые ключи

### Cхемы:

### `products`

```javascript
{
  _id: ObjectId(),  
  sku: String, 
  name: String,
  category: String,
  price: Decimal128,
  stock: [{
      geo: String, // "ekb", "nsk", прочие регионы
      qty: Int32
  }],
  attrs: {
      color: String,
      size: String,
      //прочие поля
  },
  updated_at: Date,
  version: 1 //версия схемы под будущие изменения
}
```

### `orders`

```javascript
{
  _id: ObjectId(),
  order_no: String, //что-то вроде UTN, внешний "человекочитаемый" формат          
  user_id: ObjectId,
  created_at: Date,
  geo_zone: String,
  status: "new" | "paid" | "shipped" | "done" | "canceled",
  items: [{
      product_id: ObjectId,
      qty: Int32,
      price: Decimal128
  }],
  total: Decimal128,
  version: 1 //версия схемы под будущие изменения
}
```

### `carts`

```javascript
{
  _id: ObjectId(),
  owner_key: String,// user_id или session_id
  owner_type: "user" | "guest",
  status: "active" | "ordered" | "abandoned",
  items: [{ product_id: ObjectId, quantity: Int32 }],
  created_at: Date,
  updated_at: Date,
  expires_at: Date, // TTL‑индекс, например, если будем хранить в кэше
  version: 1 //версия схемы под будущие изменения
}
```
---
### Ключи шардирования
| **Коллекция**  | **Шард‑ключ**| **Тип шардирования**  | **Причина** |
| :-: | :- | :-: | :-: |
| Products   | sku  | hashed | Наиболее подходящий кандидат для шардинга за счет уникальности, обновление склада идет по sku, поэтому решается проблема scatter gather |
| Orders | user_id | hashed  | Частые операции, связанные с поиском заказа пользователем идут по user-id, поле высоко-кардинальное. Если необходим поиск по продажам в регионах (если такое есть в контексте), то можно попробовать geo_zone индекс + zone sharding. |
| Carts | owner_key | hashed | Методом исключений и выбором высокой кардинальности: даты неподходят, status и owner_type тоже по причине низкой кардинальности -> неравномерного распределния, из высококардинального остается owner_key (user_id/session_id) |

### Команды

sh.enableSharding("somedb")

//Продукты/Товары
sh.shardCollection("somedb.products", { sku: "hashed" })

//Заказы
sh.shardCollection("somedb.orders", { user_id: "hashed" })

Если необходимо работать с регионами, то:

sh.addShardTag("shard1", "ekb")
sh.addShardTag("shard2", "nsk")

sh.addTagRange(
  "mobile_store.orders",
  { geo_zone: "ekb", user_id: MinKey },
  { geo_zone: "ekb", user_id: MaxKey },
  "ekb"
)

sh.addTagRange(
  "mobile_store.orders",
  { geo_zone: "nsk", user_id: MinKey },
  { geo_zone: "nsk", user_id: MaxKey },
  "nsk"
)

//Корзина
sh.shardCollection("somedb.carts", { owner_key: "hashed" })

**Альтернативы**
Range-шардирование было исключено из-за специфики работы с таблицами и данных (так же были отклонены все варианты шардирования по временным диапазонам в связи с низкой кардинальностью и неравномерным распределением).
На данный момент отклонен вариант с зонированием (шардированием по зонам заказов) в связи с отсутсвием необходимости формирования отчетности и прочих аналитических запросов по геозонам, т.к. требуется только сводные отчеты по всей организации.

**Недостатки, ограничения, риски**

1. Поиск в диапазоне цен по определенной категории может обойти все шарды (можно попробовать смягчить через кэш или программный слой, следящий за шардами).
2. Зональное шардирование требует дополнительного администрирования при расширении на новые регионы
3. Hashed‑ключ затрудняет range‑агрегации без дополнительного индексирования.


### <a name="_b7urdng99y53"></a>**Название:** Выявление и устранение горячих шардов
### <a name="_b7urdng99y53"></a>**Номер записи:** 2
### <a name="_hjk0fkfyohdk"></a>**Автор:** Дубовик Сергей Андреевич
### <a name="_hjk0fkfyohdk"></a>**Исполнитель:** Старший разрабочтик номер 2
### <a name="_uanumrh8zrui"></a>**Дата:** 02.08.2025
### <a name="_qmphm5d6rvi3"></a>**Контекст**
Из-за категории «Электроника» произошла перегрузка одного из шардов MongoDB, так как 70% запросов приходилось именно на эти товары. Поэтому сейчас нужно разработать стратегию, как выявлять и устранять такие «горячие» шарды, а ещё предложить метрики мониторинга, чтобы в будущем можно было предотвращать такие ситуации.

### <a name="_u8xz25hbrgql"></a>**Нефункциональные требования**

|**№**|**Требование**| **Описание** |
| :-: | :- | :-: |
|1| Observability | Необходимо соблюсти свойство прозрачности системы, чтобы реагировать на инциденты проактивно. Для этого необходимо развернуть средства логирования и мониторинга: Prometheus/Grafana, написать скрипты для сбора метрик с инстансов mongodb|

---
### <a name="_qmphm5d6rvi3"></a>**Решение**

Предлагается внедрить следующие метрики в Prometheus/Grafana (с использованием экспортера метрик):
1. Количество операций чтения/записи по шарду: mongodb_mongod_op_counters_total (shard)
2. Объем возвращенных документов: mongodb_mongod_metrics_document_returned_total
3. Количество подключений к шард-реплике: mongodb_mongod_connections{shard=...}
4. Задержки записи: mongodb_mongod_mongo_durability_latency_seconds
5. Количество перемещенных чанков: mongodb_sharding_balancer_chunks_moved_total

Метрики на уровне чанка:
1. Размер чанка: chunk.size_bytes
2. Количество чтений с чанка: chunk.reads_per_sec
3. Количество записей в чанк: chunk.writes_per_sec
4. Расчётное значение активности: chunk.hot_score


Скрипты для сбора статистики чанков:
```javascript
use config
db.chunks.aggregate([
  { $group: {
    _id: "$shard",
    totalChunks: { $sum: 1 },
    avgChunkSize: { $avg: "$size" },
    docs: { $push: "$$ROOT" }
  }}
])

sh.status()
```

опрос активности и кастомный экспорт:
cat mongos.log | grep "query" | grep collection_name | awk '{print $key}' | sort | uniq -c | sort -rn

### Устранение дисбаланса

На данный момент рассматриваются варианты:

1. Перенос данных на уровне приложения. Предлагается написать программный мигратор данных, который сбалансирует чанки или выполнит решардинг, исходя из востребованности новых категорий (шардинг по "горячим категориям" и "остальным", например, отдельный шард для электроники).
Пример потенциального решения:
Фоновый планировщик (например, cron-job или background-service), который периодически:
- Собирает метрики активности чанков (chunk.hot_score, chunk.reads_per_sec, chunk.size_bytes);
- Сравнивает текущую активность шарда с медианой кластера;
- Если активность превышает порог (например, >2x медианы), — инициирует миграцию наиболее активных чанков на менее загруженные шарды с помощью sh.moveChunk();
- Оповещает Prometheus/Grafana или логирует событие.

2. Балансировка чанков вручную или через скрипт, если проблемы с чанками:

```javascript
sh.moveChunk("products", {
  sku: "XYZ123" 
}, "shard3")
```
3. Если выключен автобалансировщик:
```javascript
sh.setBalancerState(true);
```
4. Перешардирование коллекции (нерекомендуемый способ из-за потенциального downtime):
```javascript
sh.shardCollection("products", { category: 1, sku: "hashed" })
```
5. Внедрение виртуальных шардов (если опция доступна на данный момент времени):

```javascript
{
  _id: ObjectId(),
  sku: "ABC123",
  category: "Электроника",
  vshard: NumberInt(N) //N - количество виртуальных шардов 
}

sh.shardCollection("products", { vshard: 1, sku: "hashed" })

// При вставке товара:

const vshard = Math.floor(hash(category + sku) % 32);
```

Потенциальные риски виртуальных шардов:
1. Усложнение логики в приложении (нужно помнить, как вычисляется vshard).
2. Невозможность точечного запроса по sku без знания vshard.
3. Может потребоваться вторичный индекс на sku или другие поля для компенсации.

### Альтернативные решения
1. Использовать Valkey. Популярные товары из электроники отдаются из кэша, снимая нагрузку с MongoDB. Однако от решения отказались из-за сложных фильтров(комбинаторика) и ограничений RAM.
2. Пересмотр текущих шард-ключей (например, отдельные шарды под "горячие" категории). Рабочая опция с серьезными рисками потери данных и нарушения SLA по доступности. Решено отказаться из-за недостатка опыта у администратора базы данных, что делает риск неадекватно высоким.
3. Миграция на другую базу данных с более доступными механизмами масштабирования. Решение будет обсуждено на следующем архитектурном собрании.


### <a name="_b7urdng99y53"></a>**Название:** Настройка чтения с реплик и консистентность
### <a name="_b7urdng99y53"></a>**Номер записи:** 3
### <a name="_hjk0fkfyohdk"></a>**Автор:** Дубовик Сергей Андреевич
### <a name="_hjk0fkfyohdk"></a>**Исполнитель:** Старший разрабочтик номер 3
### <a name="_uanumrh8zrui"></a>**Дата:** 02.08.2025
### <a name="_qmphm5d6rvi3"></a>**Контекст**
Из-за возросшей на систему нагрузки необходимо определить, можем ли мы перенаправить часть запросов на чтение в реплики. Необходим список операций для primary и secondary-реплик с обоснованием для последующего перенаправления запросов.

### <a name="_u8xz25hbrgql"></a>**Нефункциональные требования**

|**№**|**Требование**| **Описание** |
| :-: | :- | :-: |
|1| Data Consistency | Необходимо соблюсти требования консистености данных при обращении к репликам, определена максимальная задержка eventual consistency в 500 мс|

---
### <a name="_qmphm5d6rvi3"></a>**Решение**

|**№**|**Таблица**|**Операция**| **Тип инстанса** | **Обоснование** |
| :-: | :-: | :- | :-: | :-: |
|1| product | Поиск по фильтрам | Secondary + Cache | Средняя важность консистентности, частое чтение, можно даже закешировать (если хватит ОЗУ). Допустимая задержка ~1-2 секунды. Риск показать товар, которого нет. "Горячие" товары при этом нужно закешировать, чтобы не выводить пользователям ошибок несуществующего товара на последующих шагах. Если закешировать нет возможности, то Primary. |
|2| product | Получение карточки товара | Secondary | Более критично, чем поиск по фильтрам, желательно соблюдать консистентность по SLA, но есть возможность смягчить разницу в данных на последующих шагах (например, при оплате в разделе "подтверждения"), кроме того, атрибуты товара меняются редко. |
|3| product | Проверка наличия товара | Primary | Критично по консистентности, чтобы не продать несуществующий товар и не заниматься возвратом средств или обработкой ошибок по товарам |
|4| order | Получение истории заказов | Secondary | Редкочитаемые данные. Некритично в контексте строгой консистентности, пользователь может подождать появление нового заказа 5-10 секунд (если не оговорено обратного в SLA) |
|5| order | Отображение статуса активного заказа | Primary/Secondary | Средняя частота чтения. Зависит от механизмов идемпотентности в системе и обработки ответов в UI (лодеры и блокировка, где необходимы), чтобы пользователь не совершил повторных изменений в бд. Если все написано правильно и исключены повторные операции с деньгами, то можно переключить на Secondary. |
|6| carts | Получение корзины | Primary/Secondary | Зависит от текущего кода и наличия идемпотентости. Можно оставить на Primary, чтобы не добавить один и тот же товар параллельно. Допустимая задержка соизмерима со временем отлика нажатия на кнопку заказа - т.е. минимальна (50-100мс). |
|7| carts | Просмотр заброшенных корзин (abandoned статус) | Secondary | Данные читаются реже остальных. Неважно в контексе строгой консистентности, допустимая задержка  ~10 секунд. |

Часть решения зависит от текущей кодовой базы и обработки исключительных операций, особенно, если речь идет про заказ. Строгая консистентность рекомендуется на всех операциях, где возможны неверные расчеты стоимости или повторные списания средств. Ситуацию при невозможности достижения строгой консистености может сгладить дополнительный шаг с подтверждением данных заказа (+время на синхронзацию), идемпотентность, UI-locking.


### <a name="_b7urdng99y53"></a>**Название:** Миграция на Cassandra
### <a name="_b7urdng99y53"></a>**Номер записи:** 4
### <a name="_hjk0fkfyohdk"></a>**Автор:** Дубовик Сергей Андреевич
### <a name="_hjk0fkfyohdk"></a>**Исполнитель:** Старший разрабочтик номер 4
### <a name="_uanumrh8zrui"></a>**Дата:** 02.08.2025
### <a name="_qmphm5d6rvi3"></a>**Контекст**
Во время «чёрной пятницы» интернет-магазин использовал MongoDB с шардированием на основе диапазонов (Range-Based Sharding). При резком увеличении нагрузки (50 000 запросов/сек.) возникла высокая задержка при масштабировании:
При добавлении новых шардов MongoDB полностью перераспределяла данные между всеми узлами, что вызывало просадку latency в пик нагрузки, так как система тратила ресурсы на перемещение данных.
Руководство решило перейти на БД Cassandra, чтобы обеспечить:
Высокую отказоустойчивость (leaderless‑репликация).
Быстрое горизонтальное масштабирование без полного перераспределения данных.
Равномерное распределение данных.

### <a name="_u8xz25hbrgql"></a>**Нефункциональные требования**

|**№**|**Требование**| **Описание** |
| :-: | :- | :-: |
|1| Data Consistency | Необходимо соблюсти требования консистености данных при обращении к репликам, определена максимальная задержка eventual consistency в 500 мс. Планируется достичь приемлемого уровня консистентности за счет комбинации использования Hinted Handoff, Read Repair, Anti-Entropy Repair и установки подходящего Consistency Level |
|2| Scalability | Система нуждается в повышении способности к масштабированию без временных просадок производительности и перераспределения данных, как было с mognodb. Для оптимального применения Cassandra необходимо выделить сущности, способные к равномерному распределнию и линейному масштабированию без побочных эффектов |

---
### <a name="_qmphm5d6rvi3"></a>**Решение**

|**№**|**Сущность**|**Профиль нагрузки**| **Требование к консистентности** | **Подходит ли Cassandra?** | **Обоснование**
| :-: | :-: | :- | :-: | :-: | :-: |
|1| orders | интенсивная запись, чтение реже | высокие: заказ не теряется, но допустима eventual-consistency при чтении истории | Да | Использование Cassandra в роли append-only лога, построение PK по user_id, прием платежа по QUORUM write, дублирование статуса в кэш для надежности |
|2| carts | интенсивная запись/обновление | высокие | нет | Частые update операции нерекомендуемый способ работы со столбиковыми базами данных, под оптимизацию корзины лучше подойдет кэш
|3| products | интенсивное чтение, более редкие обновления | высокие | нет | Определенные поля могут подойти под хранение в Cassandra, но запасы требуют строгой консистентности |

Модель для пользовательскх заказов
Partition Key: user_id (равномерное распределние заказов)
Clustering: order_ts (для чтение истории)
order_ts, order_no - уникальные записи по комбинации номера + времени записи

```sql
CREATE TABLE orders_by_user (
    user_id     uuid,
    order_ts    timestamp,
    order_no    text,
    geo_zone    text,
    status      text,
    total       decimal,
    items       frozen<list<frozen<item>>>,
    PRIMARY KEY ((user_id), order_ts, order_no)
) WITH CLUSTERING ORDER BY (order_ts DESC);
```

Если необходима отчетность по регионам:
```sql
CREATE TABLE orders_by_geo (
    geo_zone   text,
    bucket_day date,
    order_ts   timestamp,
    order_no   text,
    user_id    uuid,
    total      decimal,
    PRIMARY KEY ((geo_zone, bucket_day), order_ts, order_no)
);
```

## Стратегии поддержания целостности

|**№**|**Сущность**|**Запись**| **Чтение** | **Стратегия целостности** | **Обоснование**
| :-: | :-: | :- | :-: | :-: | :-: |
|1| orders_by_user | QUORUM (кворум со всех кластеров) | LOCAL_QUORUM (кворум нод в кластере)  | Read Repair + Hinted Handoff | Заказ критичен; Hinted Handoff позволяет не потерять запись; Read Repair чинит расхождения при чтении |
|2| order_by_geo | LOCAL_QUORUM (кворум нод в кластере) | ONE (от ноды любого кластера - под отчеты) | Anti-Entropy Repair (по cron, например) | Отчеты могут работать по eventual consistency |

Если рассмотреть добавление потенциальных таблиц логов или пользовательских сессии приложения, то в этом случае можно использовать TTL или Hinted Handoff (в логе главное не потерять запись, консистентность в конечном итоге с задержкой 10-15 секунд приемлема (зависит от SLA, если оговорено, либо от стандартов проекта/организации))

## Допустимые уровни согласованности

|**№**|**Операция**|**Write**| **Read** | **Обоснование**
| :-: | :-: | :- | :-: | :-: |
|1| Создание заказа | QUORUM (кворум со всех кластеров) | - | Точность критически важна |
|2| Обновить статус | QUORUM (кворум со всех кластеров) | LOCAL_QUORUM (кворум с локального кластера) | Чтобы избежать "двойной оплаты" |
|3| История заказов | - | LOCAL_QUORUM (коврум нод в кластере) | Допускается небольшой лаг |
